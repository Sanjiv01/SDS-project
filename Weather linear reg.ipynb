{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Dataset - Temperature Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import statistics \n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset into data frame variable\n",
    "df = pd.read_csv(\"WeatherHistoryDataset.csv\")\n",
    "\n",
    "#printing the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding out the general information about the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the NaN values are represented as \" \" it has to be converted to NaN value so that we can clean the data efficiently\n",
    "df = df.replace(\" \", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of NaN values through each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Description_: \n",
    "\n",
    "- **Formatted Date**: Date in yyyy-mm-dd hr(in 24 hr format) format.\n",
    "- **Summary**: Summary of weather.\n",
    "- **Precip Type**: Type of precipitation.\n",
    "- **Temperature**: Temperature in degrees Centigrade.\n",
    "- **Apparent Temperature Â©**: Apparent temperature in degrees Centigrade.\n",
    "- **humidity**: Humidity at recorded time.\n",
    "- **Wind Speed**: Wind speed in km/hrs.\n",
    "- **Wind Bearing**: Wind Bearing in degrees.\n",
    "- **Visibility**: Visibility in km.\n",
    "- **Loud Cover**: No useful information that can be made out.\n",
    "- **Pressure**: Pressure in millibars.\n",
    "- **Daily Summary**: Present day's summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows where the Precip type and Summary is NaN\n",
    "\n",
    "df = df[df[\"Precip Type\"].notna()]\n",
    "df = df[df[\"Summary\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Loud Cover column as it does not contain useful information\n",
    "\n",
    "df.drop('Loud Cover', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Label Encoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Encoding the values of Precip Type and Summary to unique values so that we can use them for analysis\n",
    "\n",
    "df[\"Precip Type\"] = le.fit_transform(df[\"Precip Type\"])\n",
    "df[\"Summary\"] = le.fit_transform(df[\"Summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the NaN values with the mean strategy \n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(df.iloc[:,4:10].values)\n",
    "df.iloc[:,4:10] = imputer.transform(df.iloc[:,4:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows\n",
    "\n",
    "df.drop_duplicates(subset =\"Formatted Date\", keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualizing the data in boxplots to get information on the outliers\n",
    "sns.boxplot(x=df['Temperature (C)'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of outliers \n",
    "Q1 = df['Temperature (C)'].quantile(0.25)   #first quartile\n",
    "Q3 = df['Temperature (C)'].quantile(0.75)   #third quartile\n",
    "IQR = Q3 - Q1   #IQR-> Interquartile Range\n",
    "\n",
    "filter = (df['Temperature (C)'] >= Q1 - 1.5 * IQR) & (df['Temperature (C)'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Temperature (C)'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Apparent Temperature ©'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Apparent Temperature ©'].quantile(0.25)\n",
    "Q3 = df['Apparent Temperature ©'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Apparent Temperature ©'] >= Q1 - 1.5 * IQR) & (df['Apparent Temperature ©'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Apparent Temperature ©'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Humidity'].quantile(0.25)\n",
    "Q3 = df['Humidity'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Humidity'] >= Q1 - 1.5 * IQR) & (df['Humidity'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Wind Speed (km/h)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Wind Speed (km/h)'].quantile(0.25)\n",
    "Q3 = df['Wind Speed (km/h)'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Wind Speed (km/h)'] >= Q1 - 1.5 * IQR) & (df['Wind Speed (km/h)'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Wind Speed (km/h)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Wind Bearing (degrees)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Wind Bearing (degrees)'].quantile(0.25)\n",
    "Q3 = df['Wind Bearing (degrees)'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Wind Bearing (degrees)'] >= Q1 - 1.5 * IQR) & (df['Wind Bearing (degrees)'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Wind Bearing (degrees)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Visibility (km)'].quantile(0.25)\n",
    "Q3 = df['Visibility (km)'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Visibility (km)'] >= Q1 - 1.5 * IQR) & (df['Visibility (km)'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure (millibars)']=df['Pressure (millibars)'].astype(float)   #converting to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Pressure (millibars)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Pressure (millibars)'].quantile(0.25)\n",
    "Q3 = df['Pressure (millibars)'].quantile(0.75)\n",
    "IQR = Q3 - Q1     \n",
    "\n",
    "filter = (df['Pressure (millibars)'] >= Q1 - 1.5 * IQR) & (df['Pressure (millibars)'] <= Q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['Pressure (millibars)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers removed\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Visualisation - BAR GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Temperature vs Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=df['Formatted Date'], height=df['Temperature (C)'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Humidatity vs Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=df['Formatted Date'], height=df['Humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visibility vs precip type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=df['Precip Type'], height=df['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wind speed vs Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=df['Summary'], height=df['Wind Speed (km/h)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visibility vs Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=df['Summary'], height=df['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean of all required columns\n",
    "df[['Temperature (C)', 'Apparent Temperature ©', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating variance of all required columns\n",
    "df[['Temperature (C)','Apparent Temperature ©', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data before normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Temperature (C)'], 20)\n",
    "plt.xlabel('Temperature (C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Apparent Temperature ©'], 20)\n",
    "plt.xlabel('Apparent Temperature ©')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Humidity'], 20)\n",
    "plt.xlabel('Humidity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Pressure (millibars)'], 20)\n",
    "plt.xlabel('Pressure (millibars)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need for Normalization and it's effects on the Dataset\n",
    "\n",
    "    -> In the context of machine learning and data science, normalization takes the values from the database and where they are numeric columns, changes them into a common scale. \n",
    "    -> The main benefits of normalization in analytical terms are that it allows faster searching and sorting as it is better at creating indexes via smaller, logical tables. \n",
    "    -> Also, in having more tables, there is a better use of segments to control the tangible placement of data. There will be fewer nulls and redundant data after modelling any necessary columns and bias/issues with anomalies are greatly reduced by removing the differences in scale. \n",
    "    -> In summary, data normalization processes ensure that our data is structured logically and scaled proportionally where required, generally on a scale of 0 to 1. It tends to be used where you have predefined assumptions of your model. \n",
    "    -> By ensuring you have normalized data, the likelihood of success in your machine learning and data science projects vastly improves. \n",
    "    -> It is vital that organizations invest as much in ensuring the quality of their data as they do in the analytical and scientific models that are created by it. Preparation is everything in a successful data strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['Temperature (C)', 'Apparent Temperature ©', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']\n",
    "\n",
    "# Create x, where x is the values of cols as floats\n",
    "x = df[cols].values.astype(float)\n",
    "\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "df_normalized.columns = ['Temperature (C)', 'Apparent Temperature ©', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the normalized mean (to zero - 0) and variance (to one - 1)\n",
    "\n",
    "def norm (sample):\n",
    "    mean = sample.mean()\n",
    "    std = np.std(sample)\n",
    "    calc = (sample - mean)/std\n",
    "    print(f\"df_normalized[{col}].mean() = {round(calc.mean())}\")\n",
    "    print(f\"df_normalized[{col}].var() = {round(np.std(calc))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the normalized mean (to zero - 0) and variance (to one - 1)\n",
    "\n",
    "for col in cols:\n",
    "    norm(df_normalized[col]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Temperature (C)'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Temperature (C)'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Temperature (C)')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Temperature (C)'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Apparent Temperature ©'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Apparent Temperature ©'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Apparent Temperature ©')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Apparent Temperature ©'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Humidity'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Humidity'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Humidity')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Humidity'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Wind Speed (km/h)'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Wind Speed (km/h)'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Wind Speed (km/h)')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Wind Speed (km/h)'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Wind Bearing (degrees)'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Wind Bearing (degrees)'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Wind Bearing (degrees)')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Wind Bearing (degrees)'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Visibility (km)'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Visibility (km)'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Visibility (km)')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Visibility (km)'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(df_normalized['Pressure (millibars)'], 20, density=1)\n",
    "mu, sigma = scipy.stats.norm.fit(df_normalized['Pressure (millibars)'])\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "plt.xlabel('Pressure (millibars)')\n",
    "plt.plot(bins, best_fit_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(df_normalized['Pressure (millibars)'], line = 's')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of Hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For Column Temperature (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample mean and sample standard deviation\n",
    "number_of_values=len(df)            # Number of values in the column\n",
    "Sample_data=df[\"Temperature (C)\"]\n",
    "\n",
    "sample_mean=statistics.mean(Sample_data) \n",
    "sample_sd=statistics.stdev(Sample_data) \n",
    "\n",
    "# Hypothesis\n",
    "# Null Hypothesis\n",
    "# H0: The mean Temparature is 12 degree C (mu=12)\n",
    "H0=\"The mean Temparature is 12 degree C (mu=12)\"\n",
    "\n",
    "# Alternate Hypothesis\n",
    "# H1: The mean Temparature is not equal to 12 degree C (mu != 12)\n",
    "H1=\"The mean Temparature is not equal to 12 degree C (mu != 12)\"\n",
    "\n",
    "population_mean_from_hypothesis=12\n",
    "\n",
    "# Determining if the test is one tailed or two tailed and alloting alpha value\n",
    "\n",
    "test=\"two_tailed_test\"\n",
    "if(test==\"two_tailed_test\"):\n",
    "    number_of_tails=2\n",
    "    alpha = 0.025\n",
    "elif(test==\"one_tailed_test\"):\n",
    "    number_of_tails=1\n",
    "    alpha =0.05\n",
    "\n",
    "# Z score\n",
    "z_score=(sample_mean-population_mean_from_hypothesis)/(sample_sd/np.sqrt(number_of_values))\n",
    "# p Value\n",
    "p_value = scipy.stats.norm.sf(z_score) \n",
    "\n",
    "if p_value > alpha:\n",
    "    print('Null hypothesis accepted')\n",
    "    print('Accepted hypothesis is H0: ',H0)\n",
    "\n",
    "else:\n",
    "    print('Null hypothesis is rejected and alternate hypothesis is accepted')\n",
    "    print('Accepted hypothesis is H1:',H1)\n",
    "\n",
    "print('z_score=%.10f' % (z_score))\n",
    "print('p_value=%.10f' % (p_value))\n",
    "print('sample_mean=%.10f' % (sample_mean))\n",
    "print('sample_sd=%.10f' % (sample_sd))\n",
    "print('The test is '+str(number_of_tails)+' tailed test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For Column Temperature (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample mean and sample standard deviation\n",
    "number_of_values=len(df)            # Number of values in the column\n",
    "Sample_data=df[\"Temperature (C)\"]\n",
    "\n",
    "sample_mean=statistics.mean(Sample_data) \n",
    "sample_sd=statistics.stdev(Sample_data) \n",
    "\n",
    "# Hypothesis\n",
    "# Null Hypothesis\n",
    "# H0: The mean Temparature is greater than or equal to 14 degree C (mu >= 14)\n",
    "H0=\"The mean Temparature is greater than or equal to 14 degree C (mu>=14)\"\n",
    "\n",
    "# Alternate Hypothesis\n",
    "# H1: The mean Temparature is less than 14 degree C (mu < 14)\n",
    "H1=\"The mean Temparature is less than 14 degree C (mu < 14)\"\n",
    "\n",
    "population_mean_from_hypothesis=14\n",
    "\n",
    "# Determining if the test is one tailed or two tailed and alloting alpha value\n",
    "\n",
    "test=\"one_tailed_test\"\n",
    "if(test==\"two_tailed_test\"):\n",
    "    number_of_tails=2\n",
    "    alpha = 0.025\n",
    "elif(test==\"one_tailed_test\"):\n",
    "    number_of_tails=1\n",
    "    alpha =0.05\n",
    "\n",
    "# Z score\n",
    "z_score=(sample_mean-population_mean_from_hypothesis)/(sample_sd/np.sqrt(number_of_values))\n",
    "# p Value\n",
    "p_value = scipy.stats.norm.sf(z_score) \n",
    "\n",
    "if p_value > alpha:\n",
    "    print('Null hypothesis accepted')\n",
    "    print('Accepted hypothesis is H0: ',H0)\n",
    "\n",
    "else:\n",
    "    print('Null hypothesis is rejected and alternate hypothesis is accepted')\n",
    "    print('Accepted hypothesis is H1:',H1)\n",
    "\n",
    "print('z_score=%.10f' % (z_score))\n",
    "print('p_value=%.10f' % (p_value))\n",
    "print('sample_mean=%.10f' % (sample_mean))\n",
    "print('sample_sd=%.10f' % (sample_sd))\n",
    "print('The test is '+str(number_of_tails)+' tailed test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For Apparent Temperature ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample mean and sample standard deviation\n",
    "number_of_values=len(df)            # Number of values in the column\n",
    "Sample_data=df[\"Apparent Temperature ©\"]\n",
    "\n",
    "sample_mean=statistics.mean(Sample_data) \n",
    "sample_sd=statistics.stdev(Sample_data) \n",
    "\n",
    "# Hypothesis\n",
    "# Null Hypothesis\n",
    "# H0: The mean Apparent Temperature © is 11.5 degree © (mu=11.5)\n",
    "H0=\"The mean Apparent Temperature © is 11.5 degree © (mu=11.5)\"\n",
    "\n",
    "# Alternate Hypothesis\n",
    "# H1: The mean Apparent Temperature © is not equal to 11.5 degree © (mu != 11.5)\n",
    "H1=\"The mean Apparent Temperature © is not equal to 11.5 degree © (mu != 11.5)\"\n",
    "\n",
    "population_mean_from_hypothesis=11.5\n",
    "\n",
    "# Determining if the test is one tailed or two tailed and alloting alpha value\n",
    "\n",
    "test=\"two_tailed_test\"\n",
    "if(test==\"two_tailed_test\"):\n",
    "    number_of_tails=2\n",
    "    alpha = 0.025\n",
    "elif(test==\"one_tailed_test\"):\n",
    "    number_of_tails=1\n",
    "    alpha =0.05\n",
    "\n",
    "# Z score\n",
    "z_score=(sample_mean-population_mean_from_hypothesis)/(sample_sd/np.sqrt(number_of_values))\n",
    "# p Value\n",
    "p_value = scipy.stats.norm.sf(z_score) \n",
    "\n",
    "if p_value > alpha:\n",
    "    print('Null hypothesis accepted')\n",
    "    print('Accepted hypothesis is H0: ',H0)\n",
    "\n",
    "else:\n",
    "    print('Null hypothesis is rejected and alternate hypothesis is accepted')\n",
    "    print('Accepted hypothesis is H1:',H1)\n",
    "    \n",
    "print('z_score=%.10f' % (z_score))\n",
    "print('p_value=%.10f' % (p_value))\n",
    "print('sample_mean=%.10f' % (sample_mean))\n",
    "print('sample_sd=%.10f' % (sample_sd))\n",
    "print('The test is '+str(number_of_tails)+' tailed test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample mean and sample standard deviation\n",
    "number_of_values=len(df)            # Number of values in the column\n",
    "Sample_data=df[\"Humidity\"]\n",
    "\n",
    "sample_mean=statistics.mean(Sample_data) \n",
    "sample_sd=statistics.stdev(Sample_data) \n",
    "\n",
    "# Hypothesis\n",
    "# Null Hypothesis\n",
    "# H0: The mean Humidity is equal to 0.8  (mu=11.5)\n",
    "H0=\"The mean Humidity is equal to 0.8  (mu=11.5)\"\n",
    "\n",
    "# Alternate Hypothesis\n",
    "# H1: The mean Humidity is not equal to 0.8  (mu=11.5)\n",
    "H1=\"The mean Humidity is not equal to 0.8  (mu=11.5)\"\n",
    "\n",
    "population_mean_from_hypothesis=0.8\n",
    "\n",
    "# Determining if the test is one tailed or two tailed and alloting alpha value\n",
    "\n",
    "test=\"two_tailed_test\"\n",
    "if(test==\"two_tailed_test\"):\n",
    "    number_of_tails=2\n",
    "    alpha = 0.025\n",
    "elif(test==\"one_tailed_test\"):\n",
    "    number_of_tails=1\n",
    "    alpha =0.05\n",
    "\n",
    "# Z score\n",
    "z_score=(sample_mean-population_mean_from_hypothesis)/(sample_sd/np.sqrt(number_of_values))\n",
    "# p Value\n",
    "p_value = scipy.stats.norm.sf(z_score) \n",
    "\n",
    "if p_value > alpha:\n",
    "    print('Null hypothesis accepted')\n",
    "    print('Accepted hypothesis is H0: ',H0)\n",
    "\n",
    "else:\n",
    "    print('Null hypothesis is rejected and alternate hypothesis is accepted')\n",
    "    print('Accepted hypothesis is H1:',H1)\n",
    "    \n",
    "print('z_score=%.10f' % (z_score))\n",
    "print('p_value=%.10f' % (p_value))\n",
    "print('sample_mean=%.10f' % (sample_mean))\n",
    "print('sample_sd=%.10f' % (sample_sd))\n",
    "print('The test is '+str(number_of_tails)+' tailed test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Test - Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to find out if samples are correlated or not\n",
    "\n",
    "def corr_test_Pearson(FirstSample,SecondSample):\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "    correlation_const, p_value = pearsonr(FirstSample, SecondSample)\n",
    "\n",
    "    # Conclusions on the data if they are dependent or independent using p-value\n",
    "    print('correlation coefficient=%.5f, p=%5f' % (correlation_const, p_value))\n",
    "    if p_value > 0.05:\n",
    "        print('independent samples')\n",
    "    else:\n",
    "        print('dependent samples')\n",
    "\n",
    "    # Conclusions on correlation constant\n",
    "    if(correlation_const>0.6 and p_value < 0.05):\n",
    "        print(\"The given First and Second sample are positively correlated.\")\n",
    "    elif(correlation_const<-0.6 and p_value < 0.05):\n",
    "        print(\"The given First and Second sample are negatively correlated.\")\n",
    "    else:\n",
    "        print(\"The given First and Second sample are not correlated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Correlation test on Temperature (C) and Apparent Temperature ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Apparent Temperature ©'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Correlation test on Temperature (C) and Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Humidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Correlation test on Temperature (C) and Wind Speed (km/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Wind Speed (km/h)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Correlation test on Temperature (C) and Wind Bearing (degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Wind Bearing (degrees)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Correlation test on Temperature (C) and Visibility (km)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Visibility (km)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Correlation test on Temperature (C) and Pressure (millibars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Pressure (millibars)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Correlation test on Humidity and Wind Speed (km/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the check for correlation \n",
    "corr_test_Pearson(df['Temperature (C)'],df['Wind Speed (km/h)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation graphs \n",
    "\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features that will help in prediction\n",
    "\n",
    "features = ['Apparent Temperature ©','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)']\n",
    "X = df_normalized[features] \n",
    "y = df_normalized[\"Temperature (C)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit simple linear regression to training set \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def LinearReg(X_train,X_test):\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the test set results\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    \n",
    "    # Plotting the graph showing the best fit predicted values\n",
    "    plt.scatter(X_test, y_test, color = 'blue')\n",
    "    plt.plot(X_test, y_pred, color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Performing Linear Regression on Apparent Temperature © as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Apparent Temperature ©'].values.reshape(-1,1),X_test['Apparent Temperature ©'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Performing Linear Regression on Humidity as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Humidity'].values.reshape(-1,1),X_test['Humidity'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Performing Linear Regression on Wind Speed (km/h) as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Wind Speed (km/h)'].values.reshape(-1,1),X_test['Wind Speed (km/h)'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Performing Linear Regression on Wind Bearing (degrees) as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Wind Bearing (degrees)'].values.reshape(-1,1),X_test['Wind Bearing (degrees)'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Performing Linear Regression on Visibility (km) as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Visibility (km)'].values.reshape(-1,1),X_test['Visibility (km)'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Performing Linear Regression on Pressure (millibars) as independent and Temperature as dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg(X_train['Pressure (millibars)'].values.reshape(-1,1),X_test['Pressure (millibars)'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Linear regression with all the features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting simple linear regression to training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we cannot plot a scatter plot for X variable which contains all the features , therefore we cannot visualise a graph and check the best predicted values. Therefore, we have found the root mean squared error to get an idea about how good the prediction is by including all the useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the error in the prediction , lower the error better the accuracy\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "score = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
